<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="theme-color" content="#000000">
    <title>Equalized Cam</title>
    <link rel="manifest" href="manifest.json">
    <style>
        body, html { margin: 0; padding: 0; background: #000; height: 100%; overflow: hidden; display: flex; flex-direction: column; align-items: center; justify-content: center; }

        /* The canvas displays the processed video */
        canvas {
            width: 100%;
            height: auto;
            max-height: 85vh;
            object-fit: contain;
        }

        /* The raw video is hidden, we only read data from it */
        video { display: none; }

        /* Capture Button Styling */
        #capture-btn {
            position: absolute;
            bottom: 30px;
            width: 70px;
            height: 70px;
            border-radius: 50%;
            background-color: white;
            border: 4px solid #ccc;
            outline: none;
            cursor: pointer;
            box-shadow: 0 4px 10px rgba(0,0,0,0.5);
            transition: transform 0.1s;
        }
        #capture-btn:active { transform: scale(0.9); background-color: #eee; }
    </style>
</head>
<body>

    <video id="video" autoplay playsinline></video>

    <canvas id="canvas"></canvas>

    <button id="capture-btn"></button>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d', { willReadFrequently: true });
        const btn = document.getElementById('capture-btn');

        // 1. Setup Camera
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment' } // Prefer back camera
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    requestAnimationFrame(processFrame);
                };
            } catch (err) {
                console.error("Camera access denied:", err);
                alert("Camera access is required for this app.");
            }
        }

        // 2. Image Processing Loop
        function processFrame() {
            if (video.paused || video.ended) return;

            // Draw current video frame to canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Get raw pixel data
            const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = frame.data;
            const len = data.length;

            // --- Step A: Convert to Grayscale & Build Histogram ---
            const histogram = new Array(256).fill(0);

            // We iterate by 4 because pixel data is [R, G, B, A, R, G, B, A...]
            for (let i = 0; i < len; i += 4) {
                // Luminance formula
                const r = data[i];
                const g = data[i + 1];
                const b = data[i + 2];
                const gray = 0.299 * r + 0.587 * g + 0.114 * b;

                // Store grayscale temporarily in the red channel to save memory/loops
                data[i] = gray;

                // Increment histogram bucket
                histogram[Math.floor(gray)]++;
            }

            // --- Step B: Calculate CDF (Cumulative Distribution Function) ---
            const cdf = new Array(256).fill(0);
            let sum = 0;
            const totalPixels = len / 4;

            // Filter out 0 values to find min CDF (for better normalization)
            let minCdf = 0;
            for (let i = 0; i < 256; i++) {
                sum += histogram[i];
                cdf[i] = sum;
                if (minCdf === 0 && sum > 0) minCdf = sum;
            }

            // --- Step C: Apply Equalization ---
            // Pre-calculate the mapping for all 256 levels to avoid division inside the pixel loop
            const map = new Array(256);
            const range = totalPixels - minCdf;

            for(let i = 0; i < 256; i++) {
                map[i] = Math.round(((cdf[i] - minCdf) / range) * 255);
            }

            // Apply the mapping to the pixel data
            for (let i = 0; i < len; i += 4) {
                // Retrieve the grayscale value we stored in data[i]
                const originalGray = Math.floor(data[i]);
                const newGray = map[originalGray];

                data[i]     = newGray; // R
                data[i + 1] = newGray; // G
                data[i + 2] = newGray; // B
                // data[i+3] is Alpha, leave it alone
            }

            // Put processed data back
            ctx.putImageData(frame, 0, 0);

            requestAnimationFrame(processFrame);
        }

        // 3. Capture Functionality
        btn.addEventListener('click', () => {
            const link = document.createElement('a');
            link.download = `bw_eq_${Date.now()}.png`;
            link.href = canvas.toDataURL();
            link.click();
        });

        // 4. Register Service Worker
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('./sw.js');
        }

        setupCamera();
    </script>
</body>
</html>
